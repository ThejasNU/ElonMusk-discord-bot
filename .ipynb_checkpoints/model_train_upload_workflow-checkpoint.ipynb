{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTze-VbeU1c0"
   },
   "source": [
    "# Fine-tune a DialoGPT model\n",
    "\n",
    "Adapted from the notebook in [this Medium post](https://towardsdatascience.com/make-your-own-rick-sanchez-bot-with-transformers-and-dialogpt-fine-tuning-f85e6d1f4e30?gi=e4a72d1510f0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y17kuzFNUSrZ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1672,
     "status": "ok",
     "timestamp": 1636031617704,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "GBfltjGHT6KG",
    "outputId": "d4bf7c97-3c6f-4c8f-99bc-cd89486e0d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 4096,
     "status": "ok",
     "timestamp": 1636031625882,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "T8fgmjaqUErq"
   },
   "outputs": [],
   "source": [
    "!pip -q install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1636031630792,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "EtCreyG8UG1s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/My Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1636031634658,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "dnv5kT-mLsB-"
   },
   "outputs": [],
   "source": [
    "# all the imports\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import (\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmrbGB8aUmBm"
   },
   "source": [
    "## Get Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftBYBoOoV_Er"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbITTMcLVbI_"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download ruolinzheng/twewy-game-script -f twewy-name-line-full.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 1423,
     "status": "ok",
     "timestamp": 1636032373231,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "RXdJTSVwWGHj"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('elon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1636032400123,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "h6kGx-9eG7qA",
    "outputId": "ccffd9fa-59ec-446d-9071-ff02f4126cd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Joe Rogan</td>\n",
       "      <td>I'm too stupid for this conversation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>Joe Rogan</td>\n",
       "      <td>I'm sending it your way.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Joe Rogan</td>\n",
       "      <td>And so, you like that, but you also like elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>I think, also, it becomes tough. If you're lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>Okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>Yeah, we made our battery waterproof, so that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                                               line\n",
       "849   Joe Rogan              I'm too stupid for this conversation.\n",
       "1558  Joe Rogan                           I'm sending it your way.\n",
       "590   Joe Rogan  And so, you like that, but you also like elect...\n",
       "1063  Elon Musk  I think, also, it becomes tough. If you're lik...\n",
       "1483  Elon Musk                                              Okay.\n",
       "937   Elon Musk  Yeah, we made our battery waterproof, so that ..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1636032398099,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "OW3P0RFnn9hE"
   },
   "outputs": [],
   "source": [
    "data.rename(columns={\"Speaker\":\"name\",\"Text\":\"line\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1636032405773,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "u51JYHdPoYa9",
    "outputId": "01469169-71da-45c0-d940-de9461571319"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1636032420723,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "GxFgT9Itofu7",
    "outputId": "dcaa40f6-65ee-42ae-b5c8-a3d4b2fbd774"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.name==\"Elon Musk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1636032435373,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "PG8v6--qWUwj"
   },
   "outputs": [],
   "source": [
    "CHARACTER_NAME = 'Elon Musk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1636032439029,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "GZUcEMd2WLDT"
   },
   "outputs": [],
   "source": [
    "contexted = []\n",
    "\n",
    "# context window of size 7\n",
    "n = 7\n",
    "\n",
    "for i in data[data.name == CHARACTER_NAME].index:\n",
    "  if i < n:\n",
    "    continue\n",
    "  row = []\n",
    "  prev = i - 1 - n # we additionally substract 1, so row will contain current responce and 7 previous responces  \n",
    "  for j in range(i, prev, -1):\n",
    "    row.append(data.line[j])\n",
    "  contexted.append(row)\n",
    "\n",
    "columns = ['response', 'context'] \n",
    "columns = columns + ['context/' + str(i) for i in range(n - 1)]\n",
    "\n",
    "df = pd.DataFrame.from_records(contexted, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1636032442425,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "4T5OlNZHUxij",
    "outputId": "ccfc15d6-1398-45d0-8864-ddd57e8c0ab4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>It's probably pretty awkward.</td>\n",
       "      <td>Yeah, I don't think they have them at many zoo...</td>\n",
       "      <td>And not on the PJ section.</td>\n",
       "      <td>I don't think I have either.</td>\n",
       "      <td>I haven't seen bonobos at a zoo. I just probab...</td>\n",
       "      <td>Yeah. And they don't care, gay, straight, what...</td>\n",
       "      <td>It's just one stuff.</td>\n",
       "      <td>Constantly fucking, yeah. It's all they do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>It was made with the wine stem. Made with handle.</td>\n",
       "      <td>Right. Some people are just assholes. They tak...</td>\n",
       "      <td>Rough.</td>\n",
       "      <td>The sturdy people. That's just assholes. That'...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>Mason jar, wine stem and a handle, they have t...</td>\n",
       "      <td>It makes me lose faith in humanity.</td>\n",
       "      <td>It makes me-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Yes.</td>\n",
       "      <td>You're not supposed to be able to interact so ...</td>\n",
       "      <td>True.</td>\n",
       "      <td>It's weird. It's not a normal way of human int...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>Way easier.</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>... and your skull.</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>It will blow your mind-</td>\n",
       "      <td>I'll try it.</td>\n",
       "      <td>I mean, you should try Model S P100D.</td>\n",
       "      <td>The interaction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>That's correct. Living on the edge. Living on ...</td>\n",
       "      <td>Let me guess, you are a no case guy.</td>\n",
       "      <td>It's true.</td>\n",
       "      <td>That's a good point. Well, if you lose your ph...</td>\n",
       "      <td>My phone tells the time. So-</td>\n",
       "      <td>What happened?</td>\n",
       "      <td>I used to have a watch.</td>\n",
       "      <td>Ever?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>To go from one interchange to the next. If you...</td>\n",
       "      <td>Jesus.</td>\n",
       "      <td>We're about to release the software that will ...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>It's driving itself better every day.</td>\n",
       "      <td>It drives itself.</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>Like Tesla Sup, it's like the far end of elect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              response  ...                                          context/5\n",
       "157                      It's probably pretty awkward.  ...        Constantly fucking, yeah. It's all they do.\n",
       "195  It was made with the wine stem. Made with handle.  ...                                       It makes me-\n",
       "893                                               Yes.  ...                                               Yes.\n",
       "656                                              Yeah.  ...                                   The interaction.\n",
       "731  That's correct. Living on the edge. Living on ...  ...                                              Ever?\n",
       "295  To go from one interchange to the next. If you...  ...  Like Tesla Sup, it's like the far end of elect...\n",
       "\n",
       "[6 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1636032446412,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "NGy0MxMQVIAP",
    "outputId": "155878d5-f4d2-4250-b624-11b4281dd463"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yes.</td>\n",
       "      <td>So far.</td>\n",
       "      <td>I don't know. I think so. Yes.</td>\n",
       "      <td>Did it work? Was it effective?</td>\n",
       "      <td>That's why we were very clear, this is not act...</td>\n",
       "      <td>Which is why it says, \"Not a flamethrower.\"</td>\n",
       "      <td>I mean, I didn't spend much time on this flame...</td>\n",
       "      <td>Yeah. How do you have the time? How do you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Maybe it's fine. I don't know.</td>\n",
       "      <td>Is that what it is though? Maybe it's not.</td>\n",
       "      <td>It's like running the engine with no resistanc...</td>\n",
       "      <td>But why?</td>\n",
       "      <td>It sounds a little concerning.</td>\n",
       "      <td>Let's try it.</td>\n",
       "      <td>I don't know what would happen if I got into a...</td>\n",
       "      <td>What is that like?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Yes. Things are getting more and more connecte...</td>\n",
       "      <td>Do you worry or wonder, in fact, of what the n...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>It's tweaking your system more.</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>Yeah. You get more images, more video.</td>\n",
       "      <td>Limbic resonance.</td>\n",
       "      <td>Whereas, like one of the reasons why probably ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>You know, in Texas, it's kind of true. Yeah. I...</td>\n",
       "      <td>Yeah. Well, that's -- I mean, that's the armed...</td>\n",
       "      <td>It will liven things up for sure. It's guarant...</td>\n",
       "      <td>I'm like, \"Look, man, if I say something that ...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>It's not a flamethrower. Now, we've got a real...</td>\n",
       "      <td>Exactly.</td>\n",
       "      <td>Not the flamethrower, fake flamethrower here-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>It was based on two false premises. One false ...</td>\n",
       "      <td>What's dumb?</td>\n",
       "      <td>Yeah. We had like a -- It was highly modified ...</td>\n",
       "      <td>With a target top?</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>And this is when you had those cool Roadsters ...</td>\n",
       "      <td>Very close. I mean, 2008 is not a good time to...</td>\n",
       "      <td>How close did you get to folding?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              response  ...                                          context/5\n",
       "15                                                Yes.  ...  Yeah. How do you have the time? How do you hav...\n",
       "810                     Maybe it's fine. I don't know.  ...                                 What is that like?\n",
       "79   Yes. Things are getting more and more connecte...  ...  Whereas, like one of the reasons why probably ...\n",
       "543  You know, in Texas, it's kind of true. Yeah. I...  ...      Not the flamethrower, fake flamethrower here-\n",
       "613  It was based on two false premises. One false ...  ...                  How close did you get to folding?\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df, val_df = train_test_split(df, test_size=0.1)\n",
    "trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1636032450723,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "aEeJQlAKWtiJ"
   },
   "outputs": [],
   "source": [
    "# create dataset suitable for our model\n",
    "def construct_conv(row, tokenizer, eos = True):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n",
    "    conv = flatten(conv)\n",
    "    return conv\n",
    "\n",
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n",
    "\n",
    "        block_size = block_size - (tokenizer.model_max_length - tokenizer.max_len_single_sentence)\n",
    "\n",
    "        directory = args.cache_dir\n",
    "        cached_features_file = os.path.join(\n",
    "            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n",
    "        )\n",
    "\n",
    "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "            with open(cached_features_file, \"rb\") as handle:\n",
    "                self.examples = pickle.load(handle)\n",
    "        else:\n",
    "            logger.info(\"Creating features from dataset file at %s\", directory)\n",
    "\n",
    "            self.examples = []\n",
    "            for _, row in df.iterrows():\n",
    "                conv = construct_conv(row, tokenizer)\n",
    "                self.examples.append(conv)\n",
    "\n",
    "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "            with open(cached_features_file, \"wb\") as handle:\n",
    "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.examples[item], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1636032454827,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "-3iHwoKlWyrs"
   },
   "outputs": [],
   "source": [
    "# Cacheing and storing of data/checkpoints\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n",
    "    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n",
    "\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n",
    "    ordering_and_checkpoint_path = []\n",
    "\n",
    "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
    "\n",
    "    for path in glob_checkpoints:\n",
    "        if use_mtime:\n",
    "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
    "        else:\n",
    "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
    "            if regex_match and regex_match.groups():\n",
    "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
    "\n",
    "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
    "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
    "    return checkpoints_sorted\n",
    "\n",
    "\n",
    "def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n",
    "    if not args.save_total_limit:\n",
    "        return\n",
    "    if args.save_total_limit <= 0:\n",
    "        return\n",
    "\n",
    "    # Check if we should delete older checkpoint(s)\n",
    "    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n",
    "    if len(checkpoints_sorted) <= args.save_total_limit:\n",
    "        return\n",
    "\n",
    "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
    "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
    "    for checkpoint in checkpoints_to_be_deleted:\n",
    "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
    "        shutil.rmtree(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEDdTJTqUwZJ"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12298,
     "status": "ok",
     "timestamp": 1636032471100,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "r2cE0fY5UHpz",
    "outputId": "341ba2c6-bfda-4196-afbf-39d5bfcd7503"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:698: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1636032474883,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "ra2vsRp-UMXo"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
    "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
    "using a masked language modeling (MLM) loss.\n",
    "\"\"\"\n",
    "\n",
    "# Configs\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1636032478678,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "2OnASqJjUNJa"
   },
   "outputs": [],
   "source": [
    "# Args to allow for easy convertion of python script to notebook\n",
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.output_dir = 'output-small'\n",
    "        self.model_type = 'gpt2'\n",
    "        self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
    "        self.config_name = 'microsoft/DialoGPT-small'\n",
    "        self.tokenizer_name = 'microsoft/DialoGPT-small'\n",
    "        self.cache_dir = 'cached'\n",
    "        self.block_size = 512\n",
    "        self.do_train = True\n",
    "        self.do_eval = True\n",
    "        self.evaluate_during_training = False\n",
    "        self.per_gpu_train_batch_size = 2\n",
    "        self.per_gpu_eval_batch_size = 2\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.learning_rate = 5e-5\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.max_grad_norm = 1.0\n",
    "        self.num_train_epochs = 4\n",
    "        self.max_steps = -1\n",
    "        self.warmup_steps = 0\n",
    "        self.logging_steps = 1000\n",
    "        self.save_steps = 3500\n",
    "        self.save_total_limit = None\n",
    "        self.eval_all_checkpoints = False\n",
    "        self.no_cuda = False\n",
    "        self.overwrite_output_dir = True\n",
    "        self.overwrite_cache = True\n",
    "        self.should_continue = False\n",
    "        self.seed = 42\n",
    "        self.local_rank = -1\n",
    "        self.fp16 = False\n",
    "        self.fp16_opt_level = 'O1'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q1dTFXxW9NE"
   },
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 1153,
     "status": "ok",
     "timestamp": 1636032485467,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "PaarIDZrW81h"
   },
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter()\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "\n",
    "    def collate(examples: List[torch.Tensor]):\n",
    "        if tokenizer._pad_token is None:\n",
    "            return pad_sequence(examples, batch_first=True)\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n",
    "    )\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    # add_special_tokens_(model, tokenizer)\n",
    "\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    if (\n",
    "        args.model_name_or_path\n",
    "        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n",
    "        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n",
    "    ):\n",
    "        # Load in optimizer and scheduler states\n",
    "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
    "\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
    "        )\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\n",
    "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "        args.train_batch_size\n",
    "        * args.gradient_accumulation_steps\n",
    "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
    "    )\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    # Check if continuing training from a checkpoint\n",
    "    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n",
    "        try:\n",
    "            # set global_step to gobal_step of last saved checkpoint from model path\n",
    "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
    "            global_step = int(checkpoint_suffix)\n",
    "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "\n",
    "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
    "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
    "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
    "        except ValueError:\n",
    "            logger.info(\"  Starting fine-tuning.\")\n",
    "\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(\n",
    "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
    "    )\n",
    "    set_seed(args)  # Added here for reproducibility\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "\n",
    "            inputs, labels = (batch, batch)\n",
    "            if inputs.shape[1] > 1024: continue\n",
    "            inputs = inputs.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            model.train()\n",
    "            outputs = model(inputs, labels=labels)\n",
    "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                if args.fp16:\n",
    "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics\n",
    "                    if (\n",
    "                        args.local_rank == -1 and args.evaluate_during_training\n",
    "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
    "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    checkpoint_prefix = \"checkpoint\"\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    model_to_save = (\n",
    "                        model.module if hasattr(model, \"module\") else model\n",
    "                    )  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
    "\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step\n",
    "\n",
    "# Evaluation of some model\n",
    "\n",
    "def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n",
    "    os.makedirs(eval_output_dir, exist_ok=True)\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "\n",
    "    def collate(examples: List[torch.Tensor]):\n",
    "        if tokenizer._pad_token is None:\n",
    "            return pad_sequence(examples, batch_first=True)\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n",
    "    )\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        inputs, labels = (batch, batch)\n",
    "        inputs = inputs.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs, labels=labels)\n",
    "            lm_loss = outputs[0]\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "\n",
    "    result = {\"perplexity\": perplexity}\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1636032492913,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "SCnGAJWbXD9C"
   },
   "outputs": [],
   "source": [
    "# Main runner\n",
    "\n",
    "def main(df_trn, df_val):\n",
    "    args = Args()\n",
    "    \n",
    "    if args.should_continue:\n",
    "        sorted_checkpoints = _sorted_checkpoints(args)\n",
    "        if len(sorted_checkpoints) == 0:\n",
    "            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n",
    "        else:\n",
    "            args.model_name_or_path = sorted_checkpoints[-1]\n",
    "\n",
    "    if (\n",
    "        os.path.exists(args.output_dir)\n",
    "        and os.listdir(args.output_dir)\n",
    "        and args.do_train\n",
    "        and not args.overwrite_output_dir\n",
    "        and not args.should_continue\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
    "                args.output_dir\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Setup CUDA, GPU & distributed training\n",
    "    device = torch.device(\"cuda\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "    args.device = device\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
    "    )\n",
    "    logger.warning(\n",
    "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "        args.local_rank,\n",
    "        device,\n",
    "        args.n_gpu,\n",
    "        bool(args.local_rank != -1),\n",
    "        args.fp16,\n",
    "    )\n",
    "\n",
    "    # Set seed\n",
    "    set_seed(args)\n",
    "\n",
    "    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
    "    model = AutoModelWithLMHead.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        from_tf=False,\n",
    "        config=config,\n",
    "        cache_dir=args.cache_dir,\n",
    "    )\n",
    "    model.to(args.device)\n",
    "    \n",
    "    logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "    # Training\n",
    "    if args.do_train:\n",
    "        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n",
    "\n",
    "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
    "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n",
    "    if args.do_train:\n",
    "        # Create output directory if needed\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "        # They can then be reloaded using `from_pretrained()`\n",
    "        model_to_save = (\n",
    "            model.module if hasattr(model, \"module\") else model\n",
    "        )  # Take care of distributed/parallel training\n",
    "        model_to_save.save_pretrained(args.output_dir)\n",
    "        tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "        # Good practice: save your training arguments together with the trained model\n",
    "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
    "\n",
    "        # Load a trained model and vocabulary that you have fine-tuned\n",
    "        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
    "        model.to(args.device)\n",
    "\n",
    "    # Evaluation\n",
    "    results = {}\n",
    "    if args.do_eval and args.local_rank in [-1, 0]:\n",
    "        checkpoints = [args.output_dir]\n",
    "        if args.eval_all_checkpoints:\n",
    "            checkpoints = list(\n",
    "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
    "            )\n",
    "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "        for checkpoint in checkpoints:\n",
    "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
    "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
    "\n",
    "            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n",
    "            model.to(args.device)\n",
    "            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n",
    "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
    "            results.update(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 764,
     "status": "ok",
     "timestamp": 1636032498443,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "QsKrPdihMNkh"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NWvkdR-XHeB"
   },
   "source": [
    "## Run the Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697,
     "referenced_widgets": [
      "a457a9ff9a6845919912ce4fc886b945",
      "a6b4015dc19649d59c1838684a9b96c3",
      "9f9798649db24bd68103b7b133a3f77d",
      "fc1e00cb07b24148b3cb231bedbe189d",
      "f4522a8a5124484f899efded8378437d",
      "f8f71380808b4387aecd35a3da31f13a",
      "3df69f76cde44e3aa4d691cebf77759b",
      "302b9519e1f14590b8bd74a87989db43",
      "d83a28640dab412b965bc04a5c4451df",
      "9d2ae3cda2b54a9c88998d6156fe9423",
      "e2ef7342081d473482e9256b4f060268",
      "f46abcbf3b30434f86da3fc78bd2f4f7",
      "3aada3b168864c4f80bb0bf1ed41ac9a",
      "d24555dc2c1a48dcb0333e33471e9510",
      "706b115fe5904b3fb396564d6806fec2",
      "b5ae6b9186e7405bb109932b232b2fc6",
      "04e00fae021145a3ab2dd81b863a1480",
      "06a1d4033f2843dbae6a6fb928ca38b6",
      "43eb7ad6ae5c4be7b2c37484bc476e0e",
      "983e17ef910b41e7bbd6d2ceea9172ee",
      "6d051cb3a2444fb0be37c0bc6c49edac",
      "5e903dcbbd7f48ae815db065b62473f3",
      "cf11d7b97ebf456ca5be9a35c41e5ecb",
      "667d8eb34b294300be0b1a4faeae1daa",
      "2aee28f76fab4bfa880c8709c97f7069",
      "440b9ea11cc44616911f4fec914f37d0",
      "788f94c1be5645f89dda2f74804b56d4",
      "e83509f1eea84c008eaffdd6b34bcd08",
      "1f06c926fa004e558a473a2658809136",
      "4d1d5085a3ac4cd480a9f77fd218fc92",
      "bd66c78287a04618a4307b176988842d",
      "8e44a29bf4f442bcaf776463f1a81c95",
      "a01a1943e409402d8a1c630d0b077c3a",
      "6fc4ce95d1ac442d9ea4869e7e8ca78a",
      "b4eb15bed0bf46d595100d272f68cfa4",
      "b178832660e5432a9a8e2798866f2a9a",
      "957bb745350f409d960b46db74a2c354",
      "644a43db9c07421f97adf314790cf024",
      "9aedee879f8042aaab8d1e7128e35dbf",
      "fd6a9dcecfca4624ab1f8b6dbd0ba637",
      "e4a9f8e39fa242d88acd91b3e3436888",
      "3b47052d984a45cb96d8d214508a4a4e",
      "060e2d64e0604744b4a4102b7b472860",
      "8af1b638aeaa4248a6ac97cfa54dfe1d",
      "765dc4b0db0b495fa791732fafc147b2",
      "e417decf04e14f86abd1dd82222685a4",
      "3168bcc139b34b56bbfbfa1ab88a3088",
      "45ccbacb6a7946049fc7803231396b15",
      "a4e766202be545a886a5b781c85283b9",
      "382eafeb818947b081df71c845471e97",
      "c17a105d99534862a78c5dc3c4da66e7",
      "28e7b2c8f63d41c6b1ffbea428fe6207",
      "d6016028ba3e4d62b1752ac58101ebb4",
      "5c76bd77710c4e99a2c3d11869a20e77",
      "8da7c4088407431dbb34a609155bcb6c",
      "c0f17dfde9824ffb9ddf70c196948447",
      "6b5294ca0605458982928abc33a991af",
      "5ba5608121f848caaff25eee82a167d8",
      "1757146db55848f7b307099032e68af2",
      "14dae7b89a304139a26c55176046755f",
      "1005648b63604ef598b567cc9e524a09",
      "50aa427091044626b4ec9b6d76757f7a",
      "1fc5dc1155aa4f77a71c458864c6f00a",
      "0caa890aedf0490da205aff4e08f9b10",
      "d6e3833b0bc0419695cb42f146e17d8d",
      "edf678e165cc4926948078271dd7f896"
     ]
    },
    "executionInfo": {
     "elapsed": 603249,
     "status": "ok",
     "timestamp": 1636033104043,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "e61zo2JtXGNX",
    "outputId": "459df792-66b2-41b7-e728-bbba263a8b24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2021 13:28:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:698: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "11/04/2021 13:28:32 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7fba47a2bc90>\n",
      "11/04/2021 13:28:32 - INFO - __main__ -   Creating features from dataset file at cached\n",
      "11/04/2021 13:28:33 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n",
      "11/04/2021 13:28:34 - INFO - __main__ -   ***** Running training *****\n",
      "11/04/2021 13:28:34 - INFO - __main__ -     Num examples = 815\n",
      "11/04/2021 13:28:34 - INFO - __main__ -     Num Epochs = 4\n",
      "11/04/2021 13:28:34 - INFO - __main__ -     Instantaneous batch size per GPU = 2\n",
      "11/04/2021 13:28:34 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "11/04/2021 13:28:34 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "11/04/2021 13:28:34 - INFO - __main__ -     Total optimization steps = 1628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a457a9ff9a6845919912ce4fc886b945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46abcbf3b30434f86da3fc78bd2f4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf11d7b97ebf456ca5be9a35c41e5ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc4ce95d1ac442d9ea4869e7e8ca78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765dc4b0db0b495fa791732fafc147b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2021 13:38:10 - INFO - __main__ -    global_step = 1628, average loss = 2.093947668845882\n",
      "11/04/2021 13:38:10 - INFO - __main__ -   Saving model checkpoint to output-small\n",
      "11/04/2021 13:38:15 - INFO - __main__ -   Evaluate the following checkpoints: ['output-small']\n",
      "11/04/2021 13:38:18 - INFO - __main__ -   Creating features from dataset file at cached\n",
      "11/04/2021 13:38:18 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n",
      "11/04/2021 13:38:18 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "11/04/2021 13:38:18 - INFO - __main__ -     Num examples = 91\n",
      "11/04/2021 13:38:18 - INFO - __main__ -     Batch size = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f17dfde9824ffb9ddf70c196948447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2021 13:38:22 - INFO - __main__ -   ***** Eval results  *****\n",
      "11/04/2021 13:38:22 - INFO - __main__ -     perplexity = tensor(4.7186)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'perplexity_': tensor(4.7186)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(trn_df, val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRpQ_n2zXQj-"
   },
   "source": [
    "## Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11665,
     "status": "ok",
     "timestamp": 1636033129843,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "HGw3qgfaXQHX",
    "outputId": "16ba020c-2014-4f43-e4f1-dc62e4734169"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:698: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
    "model = AutoModelWithLMHead.from_pretrained('output-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36228,
     "status": "ok",
     "timestamp": 1636033169323,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "lAWsiAvNXbxd",
    "outputId": "50ff0016-7939-4702-9bc0-b3d1190caea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User:hi\n",
      "ElonBot: Hey.\n",
      ">> User:how are you?\n",
      "ElonBot: I'm okay. How are you doing?\n",
      ">> User:crypto\n",
      "ElonBot: !!!Tweet!!Fantastic!!Okay!!\n",
      ">> User:which crypto should I take?\n",
      "ElonBot: !Farthest!!What's up with that?!!You should do a video.\n"
     ]
    }
   ],
   "source": [
    "# Let's chat for 4 lines\n",
    "for step in range(4):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    # print(new_user_input_ids)\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids, max_length=200,\n",
    "        pad_token_id=tokenizer.eos_token_id,  \n",
    "        no_repeat_ngram_size=3,       \n",
    "        do_sample=True, \n",
    "        top_k=100, \n",
    "        top_p=0.7,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"ElonBot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANSQlQezXqwn"
   },
   "source": [
    "## Push Model to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1636033177924,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "cxoVZaLoTtnR"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4102,
     "status": "ok",
     "timestamp": 1636033184249,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "8sAn1ne_T0Ud",
    "outputId": "7d87ceb1-f912-4cbe-9bbd-f64681624cc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.7.4.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.62.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface_hub) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub) (3.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1636033188326,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "nC5Y5mYRU7TW"
   },
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7882,
     "status": "ok",
     "timestamp": 1636033244208,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "VgnHRgHKXwDd",
    "outputId": "2bdddfc3-e25d-45d9-a231-095b8c889003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
      "Need to get 2,129 kB of archives.\n",
      "After this operation, 7,662 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
      "Fetched 2,129 kB in 2s (880 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package git-lfs.\n",
      "(Reading database ... 155219 files and directories currently installed.)\n",
      "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
      "Unpacking git-lfs (2.3.4-1) ...\n",
      "Setting up git-lfs (2.3.4-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "executionInfo": {
     "elapsed": 764,
     "status": "ok",
     "timestamp": 1636033425151,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "uhqMtvfmXei8"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"emailid\"\n",
    "# Tip: using the same email as your huggingface.co account will link your commits to your profile\n",
    "!git config --global user.name \"username\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli repo create DialoGPT-small-elon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2449,
     "status": "ok",
     "timestamp": 1636033345452,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "s8MxXT2tWPKZ",
    "outputId": "e3312d2a-c755-488a-b946-fe92686fa851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DialoGPT-small-elon'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (3/3), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://Username:TOKEN@huggingface.co/Username/DialoGPT-small-elon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1636033349948,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "my1_OWXVWwl8",
    "outputId": "0d63be67-bc7b-4f42-cdf9-75bec783f7c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t  pytorch_model.bin\t   tokenizer.json\n",
      "eval_results.txt  special_tokens_map.json  training_args.bin\n",
      "merges.txt\t  tokenizer_config.json    vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/My Drive/output-small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 3236,
     "status": "ok",
     "timestamp": 1636033372867,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "fCKsaYEbXEvI"
   },
   "outputs": [],
   "source": [
    "!mv /content/drive/My\\ Drive/output-small/* DialoGPT-small-elon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1636033386282,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "lEW_6mvZXcIB"
   },
   "outputs": [],
   "source": [
    "os.chdir('DialoGPT-small-elon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1636033389144,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "5S5RdHR1Xm4I",
    "outputId": "4cdc903e-5e68-4cb7-b72b-9172ab6e7556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1636033391568,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "A9_S37bJXumb",
    "outputId": "dda4cfe6-3120-4cc5-8d8b-268f4be33f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t  pytorch_model.bin\t   tokenizer.json\n",
      "eval_results.txt  special_tokens_map.json  training_args.bin\n",
      "merges.txt\t  tokenizer_config.json    vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1636033395830,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "8qSr9Nj3XzI7",
    "outputId": "13318ff6-9350-4f0c-fe9b-407da70c0471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/DialoGPT-small-elon\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1636033398757,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "j1ixG7HqX7tO",
    "outputId": "3bdc8686-7ae8-409d-91e9-98f16ef07a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t\u001b[31mconfig.json\u001b[m\n",
      "\t\u001b[31meval_results.txt\u001b[m\n",
      "\t\u001b[31mmerges.txt\u001b[m\n",
      "\t\u001b[31mpytorch_model.bin\u001b[m\n",
      "\t\u001b[31mspecial_tokens_map.json\u001b[m\n",
      "\t\u001b[31mtokenizer.json\u001b[m\n",
      "\t\u001b[31mtokenizer_config.json\u001b[m\n",
      "\t\u001b[31mtraining_args.bin\u001b[m\n",
      "\t\u001b[31mvocab.json\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Kg3fVLrYAcS"
   },
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1636034109945,
     "user": {
      "displayName": "Thejas N U",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05491333396372490098"
     },
     "user_tz": -330
    },
    "id": "QoZqIFSaYFp2",
    "outputId": "0ff02b18-08b1-406f-da50-f30bbd078423",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "nothing to commit, working tree clean\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"initial commit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_XfXTCrZKmO"
   },
   "source": [
    "## All Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tIwK7G8ZLrd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model_train_upload_workflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04e00fae021145a3ab2dd81b863a1480": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "060e2d64e0604744b4a4102b7b472860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06a1d4033f2843dbae6a6fb928ca38b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0caa890aedf0490da205aff4e08f9b10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1005648b63604ef598b567cc9e524a09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14dae7b89a304139a26c55176046755f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edf678e165cc4926948078271dd7f896",
      "placeholder": "​",
      "style": "IPY_MODEL_d6e3833b0bc0419695cb42f146e17d8d",
      "value": " 45/45 [00:04&lt;00:00,  9.28it/s]"
     }
    },
    "1757146db55848f7b307099032e68af2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0caa890aedf0490da205aff4e08f9b10",
      "max": 45,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fc5dc1155aa4f77a71c458864c6f00a",
      "value": 45
     }
    },
    "1f06c926fa004e558a473a2658809136": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fc5dc1155aa4f77a71c458864c6f00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "28e7b2c8f63d41c6b1ffbea428fe6207": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2aee28f76fab4bfa880c8709c97f7069": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f06c926fa004e558a473a2658809136",
      "placeholder": "​",
      "style": "IPY_MODEL_e83509f1eea84c008eaffdd6b34bcd08",
      "value": "Iteration: 100%"
     }
    },
    "302b9519e1f14590b8bd74a87989db43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3168bcc139b34b56bbfbfa1ab88a3088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c17a105d99534862a78c5dc3c4da66e7",
      "placeholder": "​",
      "style": "IPY_MODEL_382eafeb818947b081df71c845471e97",
      "value": "Iteration: 100%"
     }
    },
    "382eafeb818947b081df71c845471e97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3aada3b168864c4f80bb0bf1ed41ac9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b47052d984a45cb96d8d214508a4a4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3df69f76cde44e3aa4d691cebf77759b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43eb7ad6ae5c4be7b2c37484bc476e0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "440b9ea11cc44616911f4fec914f37d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd66c78287a04618a4307b176988842d",
      "max": 407,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d1d5085a3ac4cd480a9f77fd218fc92",
      "value": 407
     }
    },
    "45ccbacb6a7946049fc7803231396b15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6016028ba3e4d62b1752ac58101ebb4",
      "max": 407,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_28e7b2c8f63d41c6b1ffbea428fe6207",
      "value": 407
     }
    },
    "4d1d5085a3ac4cd480a9f77fd218fc92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "50aa427091044626b4ec9b6d76757f7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ba5608121f848caaff25eee82a167d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50aa427091044626b4ec9b6d76757f7a",
      "placeholder": "​",
      "style": "IPY_MODEL_1005648b63604ef598b567cc9e524a09",
      "value": "Evaluating: 100%"
     }
    },
    "5c76bd77710c4e99a2c3d11869a20e77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e903dcbbd7f48ae815db065b62473f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644a43db9c07421f97adf314790cf024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8af1b638aeaa4248a6ac97cfa54dfe1d",
      "placeholder": "​",
      "style": "IPY_MODEL_060e2d64e0604744b4a4102b7b472860",
      "value": " 407/407 [02:24&lt;00:00,  2.55it/s]"
     }
    },
    "667d8eb34b294300be0b1a4faeae1daa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b5294ca0605458982928abc33a991af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d051cb3a2444fb0be37c0bc6c49edac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fc4ce95d1ac442d9ea4869e7e8ca78a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b178832660e5432a9a8e2798866f2a9a",
       "IPY_MODEL_957bb745350f409d960b46db74a2c354",
       "IPY_MODEL_644a43db9c07421f97adf314790cf024"
      ],
      "layout": "IPY_MODEL_b4eb15bed0bf46d595100d272f68cfa4"
     }
    },
    "706b115fe5904b3fb396564d6806fec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_983e17ef910b41e7bbd6d2ceea9172ee",
      "max": 407,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43eb7ad6ae5c4be7b2c37484bc476e0e",
      "value": 407
     }
    },
    "765dc4b0db0b495fa791732fafc147b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3168bcc139b34b56bbfbfa1ab88a3088",
       "IPY_MODEL_45ccbacb6a7946049fc7803231396b15",
       "IPY_MODEL_a4e766202be545a886a5b781c85283b9"
      ],
      "layout": "IPY_MODEL_e417decf04e14f86abd1dd82222685a4"
     }
    },
    "788f94c1be5645f89dda2f74804b56d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a01a1943e409402d8a1c630d0b077c3a",
      "placeholder": "​",
      "style": "IPY_MODEL_8e44a29bf4f442bcaf776463f1a81c95",
      "value": " 407/407 [02:22&lt;00:00,  2.44it/s]"
     }
    },
    "8af1b638aeaa4248a6ac97cfa54dfe1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8da7c4088407431dbb34a609155bcb6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e44a29bf4f442bcaf776463f1a81c95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "957bb745350f409d960b46db74a2c354": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b47052d984a45cb96d8d214508a4a4e",
      "max": 407,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4a9f8e39fa242d88acd91b3e3436888",
      "value": 407
     }
    },
    "983e17ef910b41e7bbd6d2ceea9172ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9aedee879f8042aaab8d1e7128e35dbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d2ae3cda2b54a9c88998d6156fe9423": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f9798649db24bd68103b7b133a3f77d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3df69f76cde44e3aa4d691cebf77759b",
      "placeholder": "​",
      "style": "IPY_MODEL_f8f71380808b4387aecd35a3da31f13a",
      "value": "Epoch: 100%"
     }
    },
    "a01a1943e409402d8a1c630d0b077c3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a457a9ff9a6845919912ce4fc886b945": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f9798649db24bd68103b7b133a3f77d",
       "IPY_MODEL_fc1e00cb07b24148b3cb231bedbe189d",
       "IPY_MODEL_f4522a8a5124484f899efded8378437d"
      ],
      "layout": "IPY_MODEL_a6b4015dc19649d59c1838684a9b96c3"
     }
    },
    "a4e766202be545a886a5b781c85283b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8da7c4088407431dbb34a609155bcb6c",
      "placeholder": "​",
      "style": "IPY_MODEL_5c76bd77710c4e99a2c3d11869a20e77",
      "value": " 407/407 [02:23&lt;00:00,  2.33it/s]"
     }
    },
    "a6b4015dc19649d59c1838684a9b96c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b178832660e5432a9a8e2798866f2a9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd6a9dcecfca4624ab1f8b6dbd0ba637",
      "placeholder": "​",
      "style": "IPY_MODEL_9aedee879f8042aaab8d1e7128e35dbf",
      "value": "Iteration: 100%"
     }
    },
    "b4eb15bed0bf46d595100d272f68cfa4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5ae6b9186e7405bb109932b232b2fc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e903dcbbd7f48ae815db065b62473f3",
      "placeholder": "​",
      "style": "IPY_MODEL_6d051cb3a2444fb0be37c0bc6c49edac",
      "value": " 407/407 [02:25&lt;00:00,  2.52it/s]"
     }
    },
    "bd66c78287a04618a4307b176988842d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0f17dfde9824ffb9ddf70c196948447": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ba5608121f848caaff25eee82a167d8",
       "IPY_MODEL_1757146db55848f7b307099032e68af2",
       "IPY_MODEL_14dae7b89a304139a26c55176046755f"
      ],
      "layout": "IPY_MODEL_6b5294ca0605458982928abc33a991af"
     }
    },
    "c17a105d99534862a78c5dc3c4da66e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf11d7b97ebf456ca5be9a35c41e5ecb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2aee28f76fab4bfa880c8709c97f7069",
       "IPY_MODEL_440b9ea11cc44616911f4fec914f37d0",
       "IPY_MODEL_788f94c1be5645f89dda2f74804b56d4"
      ],
      "layout": "IPY_MODEL_667d8eb34b294300be0b1a4faeae1daa"
     }
    },
    "d24555dc2c1a48dcb0333e33471e9510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06a1d4033f2843dbae6a6fb928ca38b6",
      "placeholder": "​",
      "style": "IPY_MODEL_04e00fae021145a3ab2dd81b863a1480",
      "value": "Iteration: 100%"
     }
    },
    "d6016028ba3e4d62b1752ac58101ebb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6e3833b0bc0419695cb42f146e17d8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d83a28640dab412b965bc04a5c4451df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2ef7342081d473482e9256b4f060268": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e417decf04e14f86abd1dd82222685a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4a9f8e39fa242d88acd91b3e3436888": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e83509f1eea84c008eaffdd6b34bcd08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edf678e165cc4926948078271dd7f896": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4522a8a5124484f899efded8378437d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2ef7342081d473482e9256b4f060268",
      "placeholder": "​",
      "style": "IPY_MODEL_9d2ae3cda2b54a9c88998d6156fe9423",
      "value": " 4/4 [09:36&lt;00:00, 143.86s/it]"
     }
    },
    "f46abcbf3b30434f86da3fc78bd2f4f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d24555dc2c1a48dcb0333e33471e9510",
       "IPY_MODEL_706b115fe5904b3fb396564d6806fec2",
       "IPY_MODEL_b5ae6b9186e7405bb109932b232b2fc6"
      ],
      "layout": "IPY_MODEL_3aada3b168864c4f80bb0bf1ed41ac9a"
     }
    },
    "f8f71380808b4387aecd35a3da31f13a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc1e00cb07b24148b3cb231bedbe189d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d83a28640dab412b965bc04a5c4451df",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_302b9519e1f14590b8bd74a87989db43",
      "value": 4
     }
    },
    "fd6a9dcecfca4624ab1f8b6dbd0ba637": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
